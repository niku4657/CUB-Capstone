{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e36a26f-264a-4ea8-b4a3-d9c7b51d7d40",
   "metadata": {
    "tags": []
   },
   "source": [
    " # Lane Detection\n",
    " ##### Cody Weaver \n",
    " ##### Source: https://www.sciencedirect.com/science/article/pii/S0262885603002105?casa_token=EI57d-sffaMAAAAA:wkjUpy9_k3AtEsvXlLD2Gg2wxpcxQfVMsnWSwuiy2q8eU1CKje10EderkPg0H2y1TMUiFHdBDw#FIG7\n",
    " \n",
    "## CHEVP Algorithm\n",
    "The CHEVP (Canny/Hough Estimation of Vanishing Points) algorithm is capable of detecting lanes and setting control points for paved roads. It uses a B Snake lane model and has 5 steps. \n",
    "\n",
    "##### Psuedocode:\n",
    "    Create edge map using Canny Edge Detector\n",
    "    Detect straight lines using Hough Transform\n",
    "    Detect horizon and vanishing point\n",
    "    Estimate mid line of road and boundries \n",
    "    Calculate control points\n",
    "    \n",
    "Once edges are detected the image is split horizontally into multiple sections. For each section a Hough Transform is done to look for lines in the edge map. After a Hough Transform has been applied to an image section the result looks something like this: (**this image was not split into sections**)\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/road_output.jpg\"/></p> \n",
    "\n",
    "Where the blue lines are the \"road\" lines detected by the Hough Transform. If no lines can be found for a given section of the image you can estimate the road lines using the other sections which could find lines. The vanishing point, which is just where the road \"stops\" on a given image is calculated by extending each line detected and counting intersections of pairs of lines. Each intersection of two lines votes for a vanishing point. The vanishing points are calculated for each image section seperatly. The vanishing line and horizon of the road is calculated based on the intersections of the road lines. Here is an example of what this might look like on a road from Wang et al.\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/wang_example1.jpg\"/></p>\n",
    "\n",
    "The black bar above the photos represents the horizon. Control points $Q_0, Q_1, Q_2$ are then calculated, another example from Wang et al.\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/wang_example2.jpg\"/></p>\n",
    "\n",
    "## Problems I Encountered \n",
    "\n",
    "Canny edge detection works very well for well structured roads with high contrast road markings or road boundries. However, when I applied Canny to the data Trimble gave us the result looked like this: (**White lines represent lines found by Hough Transform**)\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/test_out3.jpg\"/></p>\n",
    "\n",
    "The ground has too much noise that interferes with trying to find edges of plants and rows. There may be a way to eliminate enough noise to detect edges of rows and plants cleanly but I was not able to find such a way. However, I was able to detect some row lines using Canny but only far away from the tractor, \n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/test_out.jpg\"/></p>\n",
    "\n",
    "When I apply Canny and Hough Transform to sections of the image closer to the tractor the result is the following,\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/canny_lines.jpg\"/></p>\n",
    "\n",
    "There was nothing I tried that gave me better results.\n",
    "\n",
    "I Decided to try a different method, where instead of applying Canny I extracted the green channel of the image and then applied a color mask that detected green channel values between a given range. This gave me the following image:\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/mask.jpg\"/></p>\n",
    "\n",
    "This gives much better information about the rows near to the tractor but at longer ranges the detail is much worse. I then split the image into sections. I used 4 vertical sections and 4 horizonal sections. The horizontal sections are not used in CHEVP but they help as there are both vertical and horizontal rows in the field and only the vertical ones are needed. After splitting the image I applied a Hough Transform to the masked image section to detect lines and this resulted in the following:\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/mask_lines_example1.jpg\"/></p>\n",
    "\n",
    "Which is much cleaner and perfectly detected the rows in the middle of the image, although there were some lines found which are not parallel to the rows.\n",
    "\n",
    "However, the row lines detected are not as clean in the top half of the image,\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"img/mask_lines_example2.jpg\"/></p>\n",
    "\n",
    "This could in theory be a huge problem, if we can only detect lines beneath us it could cause a lot of issues.\n",
    "\n",
    "#### Other Problems\n",
    "\n",
    "* Didn't have time to implement the full algorithm\n",
    "* The modified method I used relies on color data, I don't know if color will be reliable to use in this way.\n",
    "* CHEVP doesn't work because there is too much noise from the ground to cleanly detect edges.\n",
    "* My method isn't as effective further away from tractor. \n",
    "* So many variables that affect the final outcome and I haven't had time to experiment with all of the possibilities.\n",
    "\n",
    "#### B-Snake lane model\n",
    "However, the lane model described by Wang et al. seems straight-forward and easy to use/understand. Maybe we can adapt this lane model to whatever our final algo is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd041c-d49f-43b0-9d68-b50965f447f2",
   "metadata": {},
   "source": [
    "#### Pseudocode for my modified algorithm\n",
    "    mask image to extract green features\n",
    "    blur masked image to reduce noise\n",
    "    split image into sections\n",
    "    for each section:\n",
    "        apply hough transform\n",
    "        #calculate vanishing points\n",
    "    #draw center line\n",
    "    #draw control points\n",
    "    \n",
    "    //I have only implemented the algorithm up to the hough transform so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc2d795-54b7-4845-8dbc-d4f87216f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e7624d-8b24-4a1a-bff6-2a59029a14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# CONST DECLARATIONS\n",
    "################################\n",
    "MASK_1 = np.asarray([36, 25, 25])\n",
    "MASK_2 = np.asarray([86,255,255])\n",
    "BLUR_KERNEL_SIZE = (7, 7)\n",
    "V_SECTIONS = 8\n",
    "H_SECTIONS = 7\n",
    "MIN_LINE_LENGTH = 1080//15\n",
    "MAX_LINE_GAP = 1080//54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81c36b7-a63b-47ec-919f-d53a13ff3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# HELPER FUNCTIONS\n",
    "################################\n",
    "# Reads Image and returns image array\n",
    "# args: string: path to image, bool: convert to hsv, bool: convert to grayscale \n",
    "def read_image(path, gray=False):\n",
    "    if gray: flag = cv2.IMREAD_GRAYSCALE\n",
    "    else: flag = cv2.IMREAD_UNCHANGED\n",
    "    \n",
    "    return cv2.imread(path, flag)\n",
    "\n",
    "# Mask image and returns\n",
    "# args: array: image in hsv format\n",
    "def mask_image(img):\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    return cv2.inRange(hsv_img, MASK_1, MASK_2)\n",
    "\n",
    "# Blur image and returns\n",
    "def blur_image(img):\n",
    "    return cv2.GaussianBlur(img, BLUR_KERNEL_SIZE, sigmaX=0, sigmaY=0)\n",
    "\n",
    "def get_section(img, section_num):\n",
    "    rows, cols = np.shape(img)\n",
    "    section = copy.deepcopy(img)\n",
    "    if section_num == 1 or section_num == 2:\n",
    "        row_range = range((section_num-1)*(rows//V_SECTIONS), (section_num)*(rows//V_SECTIONS))\n",
    "    elif section_num == 3:\n",
    "        row_range = range((section_num-1)*(rows//V_SECTIONS), (section_num+1)*(rows//V_SECTIONS))\n",
    "    elif section_num == 4:\n",
    "        row_range = range(section_num*(rows//V_SECTIONS), (section_num+4)*(rows//V_SECTIONS))\n",
    "                          \n",
    "    if section_num == 1:\n",
    "        col_range = range(3*(cols//H_SECTIONS), 4*(cols//H_SECTIONS))\n",
    "    elif section_num == 2 or section_num == 3:\n",
    "        col_range = range(2*(cols//H_SECTIONS), 5*(cols//H_SECTIONS))\n",
    "    elif section_num == 4:\n",
    "        col_range = range(1*(cols//H_SECTIONS), 6*(cols//H_SECTIONS))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (i not in row_range) or (j not in col_range):\n",
    "                section[i][j] = 0\n",
    "    \n",
    "    return section    \n",
    "\n",
    "def get_candidate_lines(lines, rows, cols):\n",
    "    candidate_lines = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if (1):#(np.abs(x2-x1) < cols//14 and np.abs(y2-y1) > rows//8):\n",
    "            candidate_lines.append(line)\n",
    "            \n",
    "    return candidate_lines       \n",
    "\n",
    "def draw_lines(img, lines):\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "            \n",
    "def extend_lines(lines, section_num):\n",
    "    extended_lines = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if (x2-x1) == 0: # finds slope\n",
    "            m = (y2-y1)/0.01\n",
    "        else:\n",
    "            m = (y2-y1)/(x2-x1)\n",
    "        b = y1\n",
    "        step = (section_num+1)*(1080//V_SECTIONS)\n",
    "        if (m > 0): # extends lines towards the top of the photo\n",
    "            extended_lines.append([[0, int((0-x1)*m+b), x2, y2]])\n",
    "        else: \n",
    "            extended_lines.append([[x1, y1, x2+step, int((x2-x1+step)*m+b)]])\n",
    "            \n",
    "    return extended_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd9e496a-1edb-45b8-a18f-aa0856267c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## \n",
    "# HOUGH LINE DETECTION\n",
    "##########################\n",
    "class Config:\n",
    "    RHO=1\n",
    "    THETA=[np.pi/3, np.pi/3, np.pi/5, np.pi/13]\n",
    "    THRESHOLD=100\n",
    "    MIN_LINE_LENGTH=[1080//15, 1080//15, 1080//15, 1080//10]\n",
    "    MAX_LINE_GAP=[0, 1080//54, 1080//27, 1080//20]\n",
    "\n",
    "def LineDetectionHelper(img, section):\n",
    "    section = section - 1 \n",
    "    lines = cv2.HoughLinesP(img, \n",
    "                            Config.RHO, \n",
    "                            Config.THETA[section], \n",
    "                            Config.THRESHOLD, \n",
    "                            minLineLength=Config.MIN_LINE_LENGTH[section], \n",
    "                            maxLineGap=Config.MAX_LINE_GAP[section]\n",
    "                           )\n",
    "    return lines\n",
    "\n",
    "def LineDetection(img):\n",
    "    lines = []\n",
    "    for section_num in range(1, 5):\n",
    "        section = get_section(img, section_num)\n",
    "        lines.append(LineDetectionHelper(section, section_num))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02eeaf61-568b-4b62-97dc-c3bcc52cb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# VANISHING POINTS ESTIMATION\n",
    "##############################\n",
    "\n",
    "def EstimateVP(img, section_num, lines):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab737ca-422c-4139-8a42-3205fae28240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = read_image('img/test_img.jpg')\n",
    "\n",
    "mask = mask_image(img)\n",
    "blurred = blur_image(mask)\n",
    "\n",
    "lines = LineDetection(blurred)\n",
    "    \n",
    "for lines in lines:\n",
    "    draw_lines(img, lines)\n",
    "\n",
    "cv2.imwrite('img/mask_lines_example.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d493531e-62bb-4dd3-b5cd-ea30bb453299",
   "metadata": {},
   "source": [
    "#### **Configs:**\n",
    "**SECTION 1:**\n",
    "- blur_kernel_size = (7, 7)\n",
    "- H_SECTIONS = 7\n",
    "- V_SECTIONS = 8\n",
    "- col_range = {3,4}\n",
    "- row_range = {1}\n",
    "- get_candidate_lines\n",
    "    - NOT USED\n",
    "    - append conditon = if (np.abs(x2-x1) < cols//64 and np.abs(y2-y1) > rows//256) \n",
    "- extend_lines\n",
    "    - extend lines math:\n",
    "            if (m > 0): # extends lines towards the top of the photo\n",
    "                extended_lines.append([[0, int((0-x1)*m+b), x2, y2]])\n",
    "            else: \n",
    "                extended_lines.append([[x1, y1, x2+50, int((x2-x1+50)*m+b)]])\n",
    "\n",
    "- HoughLinesP \n",
    "    - rho = 1\n",
    "    - theta = pi/3\n",
    "    - threshold = 100\n",
    "    - minLineLength = 1080//15\n",
    "    - maxLineGap = 0\n",
    "        \n",
    "                    \n",
    "**SECTION 2:**\n",
    "- blur_kernel_size = (7, 7)\n",
    "- H_SECTIONS = 7\n",
    "- V_SECTIONS = 8\n",
    "- col_range = {2,..,5}\n",
    "- row_range = {2}\n",
    "- get_candidate_lines\n",
    "- NOT USED\n",
    "- extend_lines\n",
    "- extend lines math:\n",
    "        step = section_num*(1080//V_SECTIONS)\n",
    "        if (m > 0): # extends lines towards the top of the photo\n",
    "            extended_lines.append([[0, int((0-x1)*m+b), x2, y2]])\n",
    "        else: \n",
    "            extended_lines.append([[x1, y1, x2+step, int((x2-x1+step)*m+b)]])\n",
    "\n",
    "- HoughLinesP \n",
    "    - rho = 1\n",
    "    - theta = pi/3\n",
    "    - threshold = 100\n",
    "    - minLineLength = 1080//15\n",
    "    - maxLineGap = 1080//54\n",
    "\n",
    "**SECTION 3:**\n",
    "- blur_kernel_size = (7, 7)\n",
    "- H_SECTIONS = 7\n",
    "- V_SECTIONS = 8\n",
    "- col_range = {2,..,5}\n",
    "- row_range = {3,..,4}\n",
    "- get_candidate_lines\n",
    "- NOT USED\n",
    "- extend_lines\n",
    "- extend lines math:\n",
    "        step = (section_num+1)*(1080//V_SECTIONS)\n",
    "        if (m > 0): # extends lines towards the top of the photo\n",
    "            extended_lines.append([[0, int((0-x1)*m+b), x2, y2]])\n",
    "        else: \n",
    "            extended_lines.append([[x1, y1, x2+step, int((x2-x1+step)*m+b)]])\n",
    "\n",
    "- HoughLinesP \n",
    "    - rho = 1\n",
    "    - theta = pi/5\n",
    "    - threshold = 100\n",
    "    - minLineLength = 1080//15\n",
    "    - maxLineGap = 1080//27\n",
    "    \n",
    "**SECTION 4:**\n",
    "- blur_kernel_size = (7, 7)\n",
    "- H_SECTIONS = 7\n",
    "- V_SECTIONS = 8\n",
    "- col_range = {1,..,6}\n",
    "- row_range = {5,..,8}\n",
    "- get_candidate_lines\n",
    "- NOT USED\n",
    "- extend_lines\n",
    "- extend lines math:\n",
    "        step = (section_num+1)*(1080//V_SECTIONS)\n",
    "        if (m > 0): # extends lines towards the top of the photo\n",
    "            extended_lines.append([[0, int((0-x1)*m+b), x2, y2]])\n",
    "        else: \n",
    "            extended_lines.append([[x1, y1, x2+step, int((x2-x1+step)*m+b)]])\n",
    "\n",
    "- HoughLinesP \n",
    "    - rho = 1\n",
    "    - theta = pi/13\n",
    "    - threshold = 100\n",
    "    - minLineLength = 1080//10\n",
    "    - maxLineGap = 1080//20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c889ce-8a8f-4b41-a96b-bf93efbabdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
